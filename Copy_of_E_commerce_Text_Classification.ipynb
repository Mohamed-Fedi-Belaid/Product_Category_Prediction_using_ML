{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOE5WcZ12Cq5xSylX99Xgj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mohamed-Fedi-Belaid/Product_Category_Prediction_using_ML/blob/main/Copy_of_E_commerce_Text_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mkqeSdXdQMr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Machine Learning Pipeline"
      ],
      "metadata": {
        "id": "BzfrYfabdmfz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **We are explected to build an api that can predict possible categories for any product. We will be using product name and it's description to find relevant categories**"
      ],
      "metadata": {
        "id": "EdEFbyLedyM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " E-commerce Text Classification\n",
        "\n",
        "With TF-IDF and Word2Vec"
      ],
      "metadata": {
        "id": "w7TETWQMd9Uo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Overview**"
      ],
      "metadata": {
        "id": "mtSyi4Xxd_gA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The objective of the project is to classify e-commerce products into four categories, based on its description available in the e-commerce platforms. The categories are: Electronics, Household, Books, and Clothing & Accessories. We carried out the following steps in this notebook:\n",
        "\n",
        "    Performed basic exploratory data analysis, comparing the distributions of the number of characters, number of words, and average word-length of descriptions of products from different categories.\n",
        "    Employed several text normalization techniques on product descriptions.\n",
        "    Used TF-IDF vectorizer on the normalized product descriptions for text vectorization, compared the baseline performance of several classifiers, and performed hyperparameter tuning on the support vector machine classifier with linear kernel.\n",
        "    In a separate direction, employed a few selected text normalization processes, namely convertion to lowercase and substitution of contractions on the raw data on product descriptions; used Google's pre-trained Word2Vec model on the tokens, obtained from the partially normalized descriptions, to get the embeddings, which are then converted to compressed sparse row (CSR) format; compared the baseline performance of several classifiers, and performed hyperparameter tuning on the XGBoost classifier.\n",
        "    Employed the model with the highest validation accuracy to predict the labels of the test observations and obtained a test accuracy of 0.948939\n",
        "\n",
        "."
      ],
      "metadata": {
        "id": "NJFWYC68eK7D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Contents**"
      ],
      "metadata": {
        "id": "Lmqv8orzeb-v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "    Introduction\n",
        "        E-commerce Product Categorization\n",
        "        Text Classification\n",
        "        Data\n",
        "        Project Objective\n",
        "    Exploratory Data Analysis\n",
        "        Class Frequencies\n",
        "        Number of Characters\n",
        "        Number of Words\n",
        "        Average Word-length\n",
        "    Train-Validation-Test Split\n",
        "    Text Normalization\n",
        "        Convertion to Lowercase\n",
        "        Removal of Whitespaces\n",
        "        Removal of Punctuations\n",
        "        Removal of Unicode Characters\n",
        "        Substitution of Acronyms\n",
        "        Substitution of Contractions\n",
        "        Removal of Stop Words\n",
        "        Spelling Correction\n",
        "        Stemming and Lemmatization\n",
        "        Discardment of Non-alphabetic Words\n",
        "        Retainment of Relevant Parts of Speech\n",
        "        Removal of Additional Stop Words\n",
        "        Integration of the Processes\n",
        "        Implementation on Product Description\n",
        "    TF-IDF Model\n",
        "        Text Vectorization\n",
        "        TF-IDF Baseline Modeling\n",
        "        TF-IDF Hyperparameter Tuning\n",
        "    Word2Vec Model\n",
        "        Partial Text Normalization\n",
        "        Word Embedding\n",
        "        Word2Vec Baseline Modeling\n",
        "        Word2Vec Hyperparameter Tuning\n",
        "    Final Prediction and Evaluation\n",
        "    Acknowledgements\n",
        "    References\n"
      ],
      "metadata": {
        "id": "KtfBT3CNefTr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Importing libraries"
      ],
      "metadata": {
        "id": "1Ci1bdZ2ejdg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File system manangement\n",
        "import time, psutil, os\n",
        "\n",
        "# Data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting and visualization\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "sns.set_theme()\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "init_notebook_mode(connected=True)\n",
        "\n",
        "# NLP\n",
        "import string, re, nltk\n",
        "from string import punctuation\n",
        "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "!pip install num2words\n",
        "from num2words import num2words\n",
        "!pip install pyspellchecker\n",
        "from spellchecker import SpellChecker\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import spacy\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Scipy\n",
        "import scipy\n",
        "from scipy import sparse\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "# Train-test split and cross validation\n",
        "from sklearn.model_selection import train_test_split, ParameterGrid\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.linear_model import RidgeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "# Model evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Others\n",
        "import json\n",
        "import gensim\n",
        "from sklearn.decomposition import TruncatedSVD"
      ],
      "metadata": {
        "id": "Lwn50D76e1Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ICO5laqNeQ4w"
      }
    }
  ]
}